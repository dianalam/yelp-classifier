{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"features: \n",
    "- average sentence length (in words)\n",
    "- average review length (in words)\n",
    "- average review length (in sentences)\n",
    "- paragraph rate\n",
    "- bulleted or numbered list rate\n",
    "- all caps, bad punctuation, run on sentences?\n",
    "- bag of words: common words in elite vs. not elite; fp, fn, etc. \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import string, re\n",
    "import math\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from spacy.en import English, STOPWORDS\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from tqdm import tqdm, tqdm_pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nlp = English()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 767,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d = nltk.Text(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reviews = pd.read_csv('data/yelp_academic_dataset_review.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stop = STOPWORDS\n",
    "punct = {p for p in string.punctuation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get descriptive features of review text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_num_words(text):\n",
    "    \"\"\"Get number of words per review.\"\"\"\n",
    "    return float(len(text.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# no spacy\n",
    "def get_num_sents(text):\n",
    "    \"\"\"Get number of sentences per review.\"\"\"\n",
    "    # add 1 at the end for last punctuation \n",
    "    return text.count('. ') + text.count('! ') + text.count('? ') + text.count(') ') + \\\n",
    "            text.count('.\\n') + text.count('!\\n') + text.count('?\\n') + text.count(')\\n') + 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_num_para(text):\n",
    "    \"\"\"Get number of paragraphs per review.\"\"\"\n",
    "    return text.count('\\n\\n') + 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 929,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mentions_price(text):\n",
    "    \"\"\"Check if review mentions price ($). Return 1 if yes, 0 if no.\"\"\"\n",
    "    return 1 if '$' in text else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 977,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_allcaps(text):\n",
    "    \"\"\"Get number of all uppercase words in review.\"\"\"\n",
    "    text = re.sub(\"[^a-zA-Z]\", \" \", text)\n",
    "    return len([word for word in text.split() if word.isupper() and len(word) > 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 941,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_exclamations(text):\n",
    "    \"\"\"Get number of exclamation marks in review.\"\"\"\n",
    "    return text.count('!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_num_chars(text):\n",
    "    return float(len([char for char in text if char != ' ' and char not in punct]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([         u'user_id',        u'review_id',             u'text',\n",
       "             u'votes.cool',      u'business_id',      u'votes.funny',\n",
       "                  u'stars',             u'date',             u'type',\n",
       "           u'votes.useful',  u'review_len_wrds',  u'review_len_sent',\n",
       "       u'avg_wrds_in_sent',         u'num_para',   u'mentions_price',\n",
       "            u'num_allcaps', u'num_exclamations',           u'tokens',\n",
       "               u'is_elite'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t = reviews.loc[0, 'text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'Mr Hoagie is an institution. Walking in, it does seem like a throwback to 30 years ago, old fashioned menu board, booths out of the 70s, and a large selection of food. Their speciality is the Italian Hoagie, and it is voted the best in the area year after year. I usually order the burger, while the patties are obviously cooked from frozen, all of the other ingredients are very fresh. Overall, its a good alternative to Subway, which is down the road.'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# bulleted or numbered list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 742,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def decode(text):\n",
    "    try:\n",
    "        return text.decode('utf8')\n",
    "    except:\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 866,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# with spacy\n",
    "def get_num_sents_spacy(text):\n",
    "    try:\n",
    "        return len([sent for sent in nlp(text).sents])\n",
    "    except:\n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get tokens -- *not currently implemented*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_clean_tokens(text):\n",
    "    #letters_only = re.sub(\"[^a-zA-Z]\", \" \", text) \n",
    "    union = punct.union(stop)\n",
    "    #spacing = {'', ' ', '\\n', '\\n\\n'}\n",
    "    tokens = [token.lemma_ for token in nlp(text.decode('utf8'))]\n",
    "    filtered = [token for token in tokens if token not in union]\n",
    "    while \"\" in filtered:\n",
    "        filtered.remove(\"\")\n",
    "    while \" \" in filtered:\n",
    "        filtered.remove(\" \")\n",
    "    while \"\\n\" in filtered:\n",
    "        filtered.remove(\"\\n\")\n",
    "    while \"\\n\\n\" in filtered:\n",
    "        filtered.remove(\"\\n\\n\")\n",
    "    return ' '.join(filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# version without utf decoding\n",
    "# def get_clean_tokens2(text):  \n",
    "#     letters_only = re.sub(\"[^a-zA-Z]\", \" \", text) \n",
    "#     words = ' '.join(letters_only.lower().split())\n",
    "#     tokens = [token.lemma_ for token in nlp(words)]\n",
    "#     filtered = [t for t in tokens if t not in stop and t != '' and t != ' ' and t != '\\n' and t != '\\n\\n']\n",
    "#     return ' '.join(filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1014,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# uses utf decoding\n",
    "def get_clean_tokens2(text):  \n",
    "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", text) \n",
    "    words = ' '.join(letters_only.lower().split())\n",
    "    tokens = [token.lemma_ for token in nlp(words)]\n",
    "    filtered = [t for t in tokens if t not in stop and t != '' and t != ' ' and t != '\\n' and t != '\\n\\n']\n",
    "    return ' '.join(filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1032,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokenize2(df):\n",
    "    return map(get_clean_tokens2, df.text.values)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1067,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokenize4(df):\n",
    "    tokens = []\n",
    "    for i in tqdm(range(len(df.text.values))):\n",
    "        tokens.append(get_clean_tokens2(df.text.values[i]))\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1071,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "clntkns = tokenize4(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1075,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('pickled/tokens.pkl', 'w') as picklefile:\n",
    "    pickle.dump(clntkns, picklefile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### parse reviews df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### OLD\n",
    "def get_features_old(df):\n",
    "    # get number of words in single review\n",
    "    df.loc[:,'review_len_wrds'] = df.loc[:,'text'].apply(lambda x: len(cleantext(x)))\n",
    "    \n",
    "    # get number of sentences in single review\n",
    "    df.loc[:,'review_len_sent'] = df.loc[:,'text'].apply(\n",
    "        lambda x: len([sent for sent in nlp(x.decode('utf8')).sents])) # better way?\n",
    "    \n",
    "    # get average number of words per sentence \n",
    "    df.loc[:,'avg_wrds_in_sent'] = df.loc[:,'review_len_wrds'] / df.loc[:,'review_len_sent']\n",
    "    \n",
    "    # get cleaned tokens for bag of words\n",
    "    df.loc[:,'clean_tkns'] = df.loc[:, 'text'].apply(lambda x: get_clean_tokens(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 969,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_features(df):\n",
    "#     decode\n",
    "    df.loc[:, 'text'] = df.loc[:, 'text'].apply(decode)\n",
    "\n",
    "    # get number of words in single review\n",
    "    df.loc[:,'review_len_wrds'] = df.loc[:,'text'].apply(get_num_words)\n",
    "\n",
    "    #get number of sentences in single review\n",
    "    df.loc[:,'review_len_sent'] = df.loc[:,'text'].apply(get_num_sents)\n",
    "\n",
    "    # get average number of words per sentence \n",
    "    df.loc[:,'avg_wrds_in_sent'] = df.loc[:,'review_len_wrds'] / df.loc[:,'review_len_sent']\n",
    "    \n",
    "    # get number of paragraphs\n",
    "    df.loc[:, 'num_para'] = df.loc[:, 'text'].apply(get_num_para)\n",
    "    \n",
    "    # check if price is mentioned\n",
    "    df.loc[:, 'mentions_price'] = df.loc[:, 'text'].apply(mentions_price)\n",
    "    \n",
    "    # get number of all caps words\n",
    "    df.loc[:, 'num_allcaps'] = df.loc[:, 'text'].apply(get_allcaps)\n",
    "    \n",
    "    # get number of exclamation marks\n",
    "    df.loc[:, 'num_exclamations'] = df.loc[:, 'text'].apply(get_exclamations)\n",
    "\n",
    "#     get cleaned tokens for bag of words\n",
    "#     %time df.loc[:,'clean_tkns'] = df.loc[:, 'text'].apply(lambda x: get_clean_tokens2(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nARI (automatic readability index) score:\\nwhere characters is the number of letters and numbers, words is the number of spaces, \\nand sentences is the number of sentences. \\n'"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# additional stuff - add to previous cell when cleaning\n",
    "def get_more_features(df):\n",
    "    df.loc[:,'num_chars'] = df.loc[:,'text'].apply(get_num_chars)\n",
    "    df.loc[:,'ari_score'] = df.apply(\n",
    "        lambda row: 4.71 * (row.num_chars/float(row.review_len_wrds)) \\\n",
    "        + 0.5 * (row.review_len_wrds/float(row.review_len_sent)) - 21.43, \n",
    "        axis = 1)\n",
    "    \n",
    "\"\"\"\n",
    "ARI (automatic readability index) score:\n",
    "where characters is the number of letters and numbers, words is the number of spaces, \n",
    "and sentences is the number of sentences. \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_chars_per_word(df):\n",
    "    df['avg_chars_per_word'] = df.loc[:,'num_chars'] / df.loc[:,'review_len_wrds']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# add elite/nonelite words\n",
    "\n",
    "def get_elite_words(tokens):\n",
    "    try:\n",
    "        tokens = tokens.split()\n",
    "        return len(elite_words.intersection(tokens))\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "def get_nonelite_words(tokens):\n",
    "    try:\n",
    "        tokens = tokens.split()\n",
    "        return len(ne_words.intersection(tokens))\n",
    "    except:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_content_counts(df):\n",
    "    df['num_elite_words'] = df.text.apply(get_elite_words)\n",
    "    df['num_ne_words'] = df.text.apply(get_nonelite_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "get_chars_per_word(reviews)\n",
    "get_features(reviews)\n",
    "get_more_features(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "add_content_counts(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "byuser = reviews.groupby('user_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "user_content = byuser.mean().loc[:, 'num_elite_words':'num_ne_words']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "user_ari = byuser.mean().loc[:,'ari_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "user_wrd_length = byuser.mean().loc[:,'avg_chars_per_word']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1003,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "user_avgs = byuser.mean().loc[:, 'review_len_wrds':]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pickle user words/content data\n",
    "with open('pickled/user_content.pkl', 'w') as picklefile:\n",
    "    pickle.dump(user_content, picklefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1009,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# pickle user avgs data\n",
    "with open('pickled/user_avgs.pkl', 'w') as picklefile:\n",
    "    pickle.dump(user_avgs, picklefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pickle user avg ari data\n",
    "with open('pickled/user_ari.pkl', 'w') as picklefile:\n",
    "    pickle.dump(user_ari, picklefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pickle user avg word length data\n",
    "with open('pickled/user_wrdlength.pkl', 'w') as picklefile:\n",
    "    pickle.dump(user_wrd_length, picklefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1077,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reviews['tokens'] = clntkns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('pickled/reviewsdf2.pkl', 'w') as picklefile:\n",
    "    pickle.dump(reviews, picklefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('pickled/reviewsdf2.pkl', 'r') as picklefile:\n",
    "    reviews = pickle.load(picklefile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bag of words, etc. workspace "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('pickled/users_elite.pkl', 'r') as picklefile:\n",
    "    userids = pickle.load(picklefile)\n",
    "    \n",
    "userids.set_index('user_id', inplace = True)\n",
    "reviews['is_elite'] = reviews.user_id.apply(lambda x: userids.loc[x, 'is_elite'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "split into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train, test = train_test_split(reviews, test_size = .25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "elite_reviews = train[train.is_elite == 1]\n",
    "nonelite_reviews = train[train.is_elite == 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "define word vector parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(analyzer = \"word\",   \\\n",
    "                             tokenizer = None,    \\\n",
    "                             preprocessor = None, \\\n",
    "                             stop_words = None, \\\n",
    "                             max_features = 500) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get most popular tokens for elite users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "elite_features = vectorizer.fit_transform(elite_reviews.tokens)\n",
    "elite_words = vectorizer.get_feature_names()\n",
    "elite_features = elite_features.toarray()\n",
    "elite_dist = np.sum(elite_features, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "elite_sorted = sorted(zip(elite_words, elite_dist), key = lambda x: x[1], reverse = True)\n",
    "elite_wrds_dict = dict(elite_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(elite_wrds_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "onlyelite_words = {\n",
    "    word : elite_wrds_dict[word] \n",
    "    for word in elite_wrds_dict \n",
    "    if word not in nonelite_wrds_dict}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# top 20 words used by elites but not non-elites\n",
    "elite_top50 = sorted(onlyelite_words.items(), key = lambda x: x[1], reverse = True)[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "elite_words = {item[0] for item in elite_top50}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get popular tokens for non-elite users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nonelite_features = vectorizer.fit_transform(nonelite_reviews.tokens)\n",
    "nonelite_words = vectorizer.get_feature_names()\n",
    "nonelite_features = nonelite_features.toarray()\n",
    "nonelite_dist = np.sum(nonelite_features, axis = 0)\n",
    "nonelite_sorted = sorted(zip(nonelite_words, nonelite_dist), key = lambda x: x[1], reverse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nonelite_wrds_dict = dict(nonelite_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "onlynonelite_words = {\n",
    "    word : nonelite_wrds_dict[word] \n",
    "    for word in nonelite_wrds_dict \n",
    "    if word not in elite_wrds_dict}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# top 50 words used by elites but not non-elites\n",
    "ne_top50 = sorted(onlynonelite_words.items(), key = lambda x: x[1], reverse = True)[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ne_words = {item[0] for item in ne_top50}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### some other stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train2 = train.dropna(subset=['tokens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# test model?\n",
    "features = vectorizer.fit_transform(train2.tokens)\n",
    "words = vectorizer.get_feature_names()\n",
    "features = features.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'place', 1347563),\n",
       " (u'good', 1237040),\n",
       " (u'food', 1206517),\n",
       " (u'great', 1039474),\n",
       " (u'time', 987742),\n",
       " (u'like', 977408),\n",
       " (u'come', 834873),\n",
       " (u'service', 815935),\n",
       " (u'order', 767823),\n",
       " (u'try', 597247),\n",
       " (u'love', 531152),\n",
       " (u've', 472226),\n",
       " (u'nice', 469437),\n",
       " (u'look', 456345),\n",
       " (u'want', 445065),\n",
       " (u'restaurant', 430650),\n",
       " (u'price', 426258),\n",
       " (u'eat', 421034),\n",
       " (u'best', 420215),\n",
       " (u'know', 397865),\n",
       " (u'think', 397360),\n",
       " (u'wait', 392371),\n",
       " (u'little', 368174),\n",
       " (u'drink', 354747),\n",
       " (u'staff', 342886),\n",
       " (u'people', 341297),\n",
       " (u'day', 340781),\n",
       " (u'ask', 331337),\n",
       " (u'thing', 330179),\n",
       " (u'friendly', 329725),\n",
       " (u'pretty', 315407),\n",
       " (u'room', 313836),\n",
       " (u'menu', 311748),\n",
       " (u'experience', 311092),\n",
       " (u'need', 308685),\n",
       " (u'tell', 308509),\n",
       " (u'chicken', 308354),\n",
       " (u'work', 308325),\n",
       " (u'night', 298637),\n",
       " (u'bar', 297164),\n",
       " (u'table', 296750),\n",
       " (u'definitely', 296024),\n",
       " (u'way', 289305),\n",
       " (u'better', 285811),\n",
       " (u'feel', 285268),\n",
       " (u'bad', 284377),\n",
       " (u'delicious', 273730),\n",
       " (u'star', 269172),\n",
       " (u'taste', 266005),\n",
       " (u'friend', 263862),\n",
       " (u'right', 262630),\n",
       " (u'lot', 262318),\n",
       " (u'vega', 261591),\n",
       " (u'amazing', 258373),\n",
       " (u'new', 257560),\n",
       " (u'recommend', 255679),\n",
       " (u'hour', 247641),\n",
       " (u'use', 247512),\n",
       " (u'minute', 246556),\n",
       " (u'pizza', 245235),\n",
       " (u'sauce', 234239),\n",
       " (u'sure', 232820),\n",
       " (u'check', 228986),\n",
       " (u'cheese', 227437),\n",
       " (u'year', 225926),\n",
       " (u'walk', 223581),\n",
       " (u'salad', 223537),\n",
       " (u'meal', 222750),\n",
       " (u'fresh', 220706),\n",
       " (u'review', 220601),\n",
       " (u'leave', 219726),\n",
       " (u'burger', 219547),\n",
       " (u'small', 217001),\n",
       " (u'visit', 216077),\n",
       " (u'location', 213373),\n",
       " (u'area', 212612),\n",
       " (u'customer', 211085),\n",
       " (u'enjoy', 210243),\n",
       " (u'bit', 206874),\n",
       " (u'big', 206131),\n",
       " (u'dish', 205793),\n",
       " (u'll', 204150),\n",
       " (u'lunch', 202936),\n",
       " (u'flavor', 196651),\n",
       " (u'pay', 196317),\n",
       " (u'sit', 195513),\n",
       " (u'wasn', 195005),\n",
       " (u'awesome', 193017),\n",
       " (u'long', 191897),\n",
       " (u'clean', 191207),\n",
       " (u'dinner', 188752),\n",
       " (u'stay', 185797),\n",
       " (u'happy', 185574),\n",
       " (u'serve', 183981),\n",
       " (u'sandwich', 181423),\n",
       " (u'server', 180294),\n",
       " (u'favorite', 178743),\n",
       " (u'bring', 178378),\n",
       " (u'beer', 176966),\n",
       " (u'store', 172781)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # get counts for each word in corpus \n",
    "# dist = np.sum(features, axis = 0)\n",
    "# sorted(zip(words, dist), key = lambda x: x[1], reverse = True)[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = GaussianNB().fit(features, train2.is_elite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_features = vectorizer.fit_transform(test.tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_features = test_features.toarray()\n",
    "test_pred = model.predict(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.718772469729\n",
      "0.43614221322\n",
      "0.512898933237\n"
     ]
    }
   ],
   "source": [
    "print accuracy_score(test.is_elite, test_pred)\n",
    "print precision_score(test.is_elite, test_pred)\n",
    "print recall_score(test.is_elite, test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75549519687077571"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.is_elite.value_counts()[0] / float(test.is_elite.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = model.predict(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.727847081121\n",
      "0.448259404194\n",
      "0.485176924527\n"
     ]
    }
   ],
   "source": [
    "print accuracy_score(train.is_elite, pred)\n",
    "print precision_score(train.is_elite, pred)\n",
    "print recall_score(train.is_elite, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 1.0\n",
      "acc: [ 1.  1.]\n",
      "acc: [ 1.  1.]\n",
      "acc: [ 1.  1.]\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(features)\n",
    "print 'acc:', accuracy_score(test.is_elite, pred)\n",
    "print 'acc:', precision_score(test.is_elite, pred, average = None)\n",
    "print 'acc:', recall_score(test.is_elite, pred, average = None)\n",
    "print 'acc:', f1_score(test.is_elite, pred, average = None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
