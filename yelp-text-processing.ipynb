{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"features: \n",
    "- average sentence length (in words)\n",
    "- average review length (in words)\n",
    "- average review length (in sentences)\n",
    "- paragraph rate\n",
    "- bulleted or numbered list rate\n",
    "- all caps, bad punctuation, run on sentences?\n",
    "- bag of words: common words in elite vs. not elite; fp, fn, etc. \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 980,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import string, re\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from spacy.en import English, STOPWORDS\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from tqdm import tqdm, tqdm_pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nlp = English()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 767,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d = nltk.Text(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reviews = pd.read_csv('data/yelp_academic_dataset_review.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stop = STOPWORDS\n",
    "punct = {p for p in string.punctuation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get descriptive features of review text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 948,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_num_words(text):\n",
    "    \"\"\"Get number of words per review.\"\"\"\n",
    "    return len(text.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 949,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# no spacy\n",
    "def get_num_sents(text):\n",
    "    \"\"\"Get number of sentences per review.\"\"\"\n",
    "    # add 1 at the end for last punctuation \n",
    "    return text.count('. ') + text.count('! ') + text.count('? ') + text.count(') ') + \\\n",
    "            text.count('.\\n') + text.count('!\\n') + text.count('?\\n') + text.count(')\\n') + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 904,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_num_para(text):\n",
    "    \"\"\"Get number of paragraphs per review.\"\"\"\n",
    "    return text.count('\\n\\n') + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 929,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mentions_price(text):\n",
    "    \"\"\"Check if review mentions price ($). Return 1 if yes, 0 if no.\"\"\"\n",
    "    return 1 if '$' in text else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 977,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_allcaps(text):\n",
    "    \"\"\"Get number of all uppercase words in review.\"\"\"\n",
    "    text = re.sub(\"[^a-zA-Z]\", \" \", text)\n",
    "    return len([word for word in text.split() if word.isupper() and len(word) > 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 941,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_exclamations(text):\n",
    "    \"\"\"Get number of exclamation marks in review.\"\"\"\n",
    "    return text.count('!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# bulleted or numbered list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 742,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def decode(text):\n",
    "    try:\n",
    "        return text.decode('utf8')\n",
    "    except:\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 866,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# with spacy\n",
    "def get_num_sents_spacy(text):\n",
    "    try:\n",
    "        return len([sent for sent in nlp(text).sents])\n",
    "    except:\n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get tokens -- *not currently implemented*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_clean_tokens(text):\n",
    "    #letters_only = re.sub(\"[^a-zA-Z]\", \" \", text) \n",
    "    union = punct.union(stop)\n",
    "    #spacing = {'', ' ', '\\n', '\\n\\n'}\n",
    "    tokens = [token.lemma_ for token in nlp(text.decode('utf8'))]\n",
    "    filtered = [token for token in tokens if token not in union]\n",
    "    while \"\" in filtered:\n",
    "        filtered.remove(\"\")\n",
    "    while \" \" in filtered:\n",
    "        filtered.remove(\" \")\n",
    "    while \"\\n\" in filtered:\n",
    "        filtered.remove(\"\\n\")\n",
    "    while \"\\n\\n\" in filtered:\n",
    "        filtered.remove(\"\\n\\n\")\n",
    "    return ' '.join(filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# version without utf decoding\n",
    "# def get_clean_tokens2(text):  \n",
    "#     letters_only = re.sub(\"[^a-zA-Z]\", \" \", text) \n",
    "#     words = ' '.join(letters_only.lower().split())\n",
    "#     tokens = [token.lemma_ for token in nlp(words)]\n",
    "#     filtered = [t for t in tokens if t not in stop and t != '' and t != ' ' and t != '\\n' and t != '\\n\\n']\n",
    "#     return ' '.join(filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 686,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# uses utf decoding\n",
    "def get_clean_tokens2(text):  \n",
    "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", text) \n",
    "    words = ' '.join(letters_only.lower().split())\n",
    "    tokens = [token.lemma_ for token in nlp(words)]\n",
    "    filtered = [t for t in tokens if t not in stop and t != '' and t != ' ' and t != '\\n' and t != '\\n\\n']\n",
    "    return ' '.join(filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### parse reviews df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### OLD\n",
    "def get_features_old(df):\n",
    "    # get number of words in single review\n",
    "    df.loc[:,'review_len_wrds'] = df.loc[:,'text'].apply(lambda x: len(cleantext(x)))\n",
    "    \n",
    "    # get number of sentences in single review\n",
    "    df.loc[:,'review_len_sent'] = df.loc[:,'text'].apply(\n",
    "        lambda x: len([sent for sent in nlp(x.decode('utf8')).sents])) # better way?\n",
    "    \n",
    "    # get average number of words per sentence \n",
    "    df.loc[:,'avg_wrds_in_sent'] = df.loc[:,'review_len_wrds'] / df.loc[:,'review_len_sent']\n",
    "    \n",
    "    # get cleaned tokens for bag of words\n",
    "    df.loc[:,'clean_tkns'] = df.loc[:, 'text'].apply(lambda x: get_clean_tokens(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 969,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_features(df):\n",
    "#     decode\n",
    "    df.loc[:, 'text'] = df.loc[:, 'text'].apply(decode)\n",
    "\n",
    "    # get number of words in single review\n",
    "    df.loc[:,'review_len_wrds'] = df.loc[:,'text'].apply(get_num_words)\n",
    "\n",
    "    #get number of sentences in single review\n",
    "    df.loc[:,'review_len_sent'] = df.loc[:,'text'].apply(get_num_sents)\n",
    "\n",
    "    # get average number of words per sentence \n",
    "    df.loc[:,'avg_wrds_in_sent'] = df.loc[:,'review_len_wrds'] / df.loc[:,'review_len_sent']\n",
    "    \n",
    "    # get number of paragraphs\n",
    "    df.loc[:, 'num_para'] = df.loc[:, 'text'].apply(get_num_para)\n",
    "    \n",
    "    # check if price is mentioned\n",
    "    df.loc[:, 'mentions_price'] = df.loc[:, 'text'].apply(mentions_price)\n",
    "    \n",
    "    # get number of all caps words\n",
    "    df.loc[:, 'num_allcaps'] = df.loc[:, 'text'].apply(get_allcaps)\n",
    "    \n",
    "    # get number of exclamation marks\n",
    "    df.loc[:, 'num_exclamations'] = df.loc[:, 'text'].apply(get_exclamations)\n",
    "\n",
    "#     get cleaned tokens for bag of words\n",
    "#     %time df.loc[:,'clean_tkns'] = df.loc[:, 'text'].apply(lambda x: get_clean_tokens2(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 986,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "get_features(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 988,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('pickled/reviewsdf.pkl', 'w') as picklefile:\n",
    "    pickle.dump(reviews, picklefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1010,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>review_id</th>\n",
       "      <th>text</th>\n",
       "      <th>votes.cool</th>\n",
       "      <th>business_id</th>\n",
       "      <th>votes.funny</th>\n",
       "      <th>stars</th>\n",
       "      <th>date</th>\n",
       "      <th>type</th>\n",
       "      <th>votes.useful</th>\n",
       "      <th>review_len_wrds</th>\n",
       "      <th>review_len_sent</th>\n",
       "      <th>avg_wrds_in_sent</th>\n",
       "      <th>num_para</th>\n",
       "      <th>mentions_price</th>\n",
       "      <th>num_allcaps</th>\n",
       "      <th>num_exclamations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1349168</th>\n",
       "      <td>AckuDQQQ7d4tKE8IOZ0ttw</td>\n",
       "      <td>ccE-yH9ROF5EChmHc4QTdw</td>\n",
       "      <td>This place was amazing. I'm writing this revie...</td>\n",
       "      <td>0</td>\n",
       "      <td>vSf0pqvaLp5sVSjJPeOqqQ</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2015-02-11</td>\n",
       "      <td>review</td>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "      <td>6</td>\n",
       "      <td>13.333333</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        user_id               review_id  \\\n",
       "1349168  AckuDQQQ7d4tKE8IOZ0ttw  ccE-yH9ROF5EChmHc4QTdw   \n",
       "\n",
       "                                                      text  votes.cool  \\\n",
       "1349168  This place was amazing. I'm writing this revie...           0   \n",
       "\n",
       "                    business_id  votes.funny  stars        date    type  \\\n",
       "1349168  vSf0pqvaLp5sVSjJPeOqqQ            0      5  2015-02-11  review   \n",
       "\n",
       "         votes.useful  review_len_wrds  review_len_sent  avg_wrds_in_sent  \\\n",
       "1349168             0               80                6         13.333333   \n",
       "\n",
       "         num_para  mentions_price  num_allcaps  num_exclamations  \n",
       "1349168         1               0            1                 0  "
      ]
     },
     "execution_count": 1010,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews[reviews.user_id == 'AckuDQQQ7d4tKE8IOZ0ttw']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 993,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "byuser = reviews.groupby('user_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 998,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15.366146458583433"
      ]
     },
     "execution_count": 998,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "128/8.33"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1003,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "user_avgs = byuser.mean().loc[:, 'review_len_wrds':]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1009,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# pickle user avgs data\n",
    "with open('pickled/user_avgs.pkl', 'w') as picklefile:\n",
    "    pickle.dump(user_avgs, picklefile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bag of words, etc. workspace -- *not implemented*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test model?\n",
    "vectorizer = CountVectorizer(analyzer = \"word\",   \\\n",
    "                             tokenizer = None,    \\\n",
    "                             preprocessor = None, \\\n",
    "                             stop_words = None) \n",
    "features = vectorizer.fit_transform(test.clean_tkns)\n",
    "words = vectorizer.get_feature_names()\n",
    "features = features.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get counts for each word in corpus \n",
    "dist = np.sum(features, axis = 0)\n",
    "print sorted(zip(words, dist), key = lambda x: x[1], reverse = True)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_estimators = 50).fit(features, test.is_elite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 1.0\n",
      "acc: [ 1.  1.]\n",
      "acc: [ 1.  1.]\n",
      "acc: [ 1.  1.]\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(features)\n",
    "print 'acc:', accuracy_score(test.is_elite, pred)\n",
    "print 'acc:', precision_score(test.is_elite, pred, average = None)\n",
    "print 'acc:', recall_score(test.is_elite, pred, average = None)\n",
    "print 'acc:', f1_score(test.is_elite, pred, average = None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
