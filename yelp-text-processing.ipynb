{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"features: \n",
    "- average sentence length (in words)\n",
    "- average review length (in words)\n",
    "- average review length (in sentences)\n",
    "- paragraph rate\n",
    "- bulleted or numbered list rate\n",
    "- all caps, bad punctuation, run on sentences?\n",
    "- bag of words: common words in elite vs. not elite; fp, fn, etc. \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import string, re\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from spacy.en import English, STOPWORDS\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from tqdm import tqdm, tqdm_pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nlp = English()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 767,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d = nltk.Text(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reviews = pd.read_csv('data/yelp_academic_dataset_review.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stop = STOPWORDS\n",
    "punct = {p for p in string.punctuation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get descriptive features of review text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 948,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_num_words(text):\n",
    "    \"\"\"Get number of words per review.\"\"\"\n",
    "    return len(text.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 949,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# no spacy\n",
    "def get_num_sents(text):\n",
    "    \"\"\"Get number of sentences per review.\"\"\"\n",
    "    # add 1 at the end for last punctuation \n",
    "    return text.count('. ') + text.count('! ') + text.count('? ') + text.count(') ') + \\\n",
    "            text.count('.\\n') + text.count('!\\n') + text.count('?\\n') + text.count(')\\n') + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 904,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_num_para(text):\n",
    "    \"\"\"Get number of paragraphs per review.\"\"\"\n",
    "    return text.count('\\n\\n') + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 929,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mentions_price(text):\n",
    "    \"\"\"Check if review mentions price ($). Return 1 if yes, 0 if no.\"\"\"\n",
    "    return 1 if '$' in text else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 977,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_allcaps(text):\n",
    "    \"\"\"Get number of all uppercase words in review.\"\"\"\n",
    "    text = re.sub(\"[^a-zA-Z]\", \" \", text)\n",
    "    return len([word for word in text.split() if word.isupper() and len(word) > 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 941,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_exclamations(text):\n",
    "    \"\"\"Get number of exclamation marks in review.\"\"\"\n",
    "    return text.count('!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# bulleted or numbered list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 742,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def decode(text):\n",
    "    try:\n",
    "        return text.decode('utf8')\n",
    "    except:\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 866,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# with spacy\n",
    "def get_num_sents_spacy(text):\n",
    "    try:\n",
    "        return len([sent for sent in nlp(text).sents])\n",
    "    except:\n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get tokens -- *not currently implemented*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_clean_tokens(text):\n",
    "    #letters_only = re.sub(\"[^a-zA-Z]\", \" \", text) \n",
    "    union = punct.union(stop)\n",
    "    #spacing = {'', ' ', '\\n', '\\n\\n'}\n",
    "    tokens = [token.lemma_ for token in nlp(text.decode('utf8'))]\n",
    "    filtered = [token for token in tokens if token not in union]\n",
    "    while \"\" in filtered:\n",
    "        filtered.remove(\"\")\n",
    "    while \" \" in filtered:\n",
    "        filtered.remove(\" \")\n",
    "    while \"\\n\" in filtered:\n",
    "        filtered.remove(\"\\n\")\n",
    "    while \"\\n\\n\" in filtered:\n",
    "        filtered.remove(\"\\n\\n\")\n",
    "    return ' '.join(filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# version without utf decoding\n",
    "# def get_clean_tokens2(text):  \n",
    "#     letters_only = re.sub(\"[^a-zA-Z]\", \" \", text) \n",
    "#     words = ' '.join(letters_only.lower().split())\n",
    "#     tokens = [token.lemma_ for token in nlp(words)]\n",
    "#     filtered = [t for t in tokens if t not in stop and t != '' and t != ' ' and t != '\\n' and t != '\\n\\n']\n",
    "#     return ' '.join(filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1014,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# uses utf decoding\n",
    "def get_clean_tokens2(text):  \n",
    "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", text) \n",
    "    words = ' '.join(letters_only.lower().split())\n",
    "    tokens = [token.lemma_ for token in nlp(words)]\n",
    "    filtered = [t for t in tokens if t not in stop and t != '' and t != ' ' and t != '\\n' and t != '\\n\\n']\n",
    "    return ' '.join(filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1015,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokenize(df):\n",
    "    # get cleaned tokens for bag of words\n",
    "    df.loc[:,'clean_tkns'] = df.loc[:, 'text'].apply(get_clean_tokens2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1032,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokenize2(df):\n",
    "    return map(get_clean_tokens2, df.text.values)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1038,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokenize3(df):\n",
    "    f = np.vectorize(get_clean_tokens2)\n",
    "    return f(df.text.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1067,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokenize4(df):\n",
    "    tokens = []\n",
    "    for i in tqdm(range(len(df.text.values))):\n",
    "        tokens.append(get_clean_tokens2(df.text.values[i]))\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1071,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "clntkns = tokenize4(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1074,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2225213"
      ]
     },
     "execution_count": 1074,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(clntkns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1075,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('pickled/tokens.pkl', 'w') as picklefile:\n",
    "    pickle.dump(clntkns, picklefile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### parse reviews df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### OLD\n",
    "def get_features_old(df):\n",
    "    # get number of words in single review\n",
    "    df.loc[:,'review_len_wrds'] = df.loc[:,'text'].apply(lambda x: len(cleantext(x)))\n",
    "    \n",
    "    # get number of sentences in single review\n",
    "    df.loc[:,'review_len_sent'] = df.loc[:,'text'].apply(\n",
    "        lambda x: len([sent for sent in nlp(x.decode('utf8')).sents])) # better way?\n",
    "    \n",
    "    # get average number of words per sentence \n",
    "    df.loc[:,'avg_wrds_in_sent'] = df.loc[:,'review_len_wrds'] / df.loc[:,'review_len_sent']\n",
    "    \n",
    "    # get cleaned tokens for bag of words\n",
    "    df.loc[:,'clean_tkns'] = df.loc[:, 'text'].apply(lambda x: get_clean_tokens(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 969,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_features(df):\n",
    "#     decode\n",
    "    df.loc[:, 'text'] = df.loc[:, 'text'].apply(decode)\n",
    "\n",
    "    # get number of words in single review\n",
    "    df.loc[:,'review_len_wrds'] = df.loc[:,'text'].apply(get_num_words)\n",
    "\n",
    "    #get number of sentences in single review\n",
    "    df.loc[:,'review_len_sent'] = df.loc[:,'text'].apply(get_num_sents)\n",
    "\n",
    "    # get average number of words per sentence \n",
    "    df.loc[:,'avg_wrds_in_sent'] = df.loc[:,'review_len_wrds'] / df.loc[:,'review_len_sent']\n",
    "    \n",
    "    # get number of paragraphs\n",
    "    df.loc[:, 'num_para'] = df.loc[:, 'text'].apply(get_num_para)\n",
    "    \n",
    "    # check if price is mentioned\n",
    "    df.loc[:, 'mentions_price'] = df.loc[:, 'text'].apply(mentions_price)\n",
    "    \n",
    "    # get number of all caps words\n",
    "    df.loc[:, 'num_allcaps'] = df.loc[:, 'text'].apply(get_allcaps)\n",
    "    \n",
    "    # get number of exclamation marks\n",
    "    df.loc[:, 'num_exclamations'] = df.loc[:, 'text'].apply(get_exclamations)\n",
    "\n",
    "#     get cleaned tokens for bag of words\n",
    "#     %time df.loc[:,'clean_tkns'] = df.loc[:, 'text'].apply(lambda x: get_clean_tokens2(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 986,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "get_features(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 993,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "byuser = reviews.groupby('user_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1003,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "user_avgs = byuser.mean().loc[:, 'review_len_wrds':]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1009,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# pickle user avgs data\n",
    "with open('pickled/user_avgs.pkl', 'w') as picklefile:\n",
    "    pickle.dump(user_avgs, picklefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1077,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reviews['tokens'] = clntkns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('pickled/reviewsdf2.pkl', 'w') as picklefile:\n",
    "    pickle.dump(reviews, picklefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('pickled/reviewsdf2.pkl', 'r') as picklefile:\n",
    "    reviews = pickle.load(picklefile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bag of words, etc. workspace -- *not implemented*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([         u'user_id',        u'review_id',             u'text',\n",
       "             u'votes.cool',      u'business_id',      u'votes.funny',\n",
       "                  u'stars',             u'date',             u'type',\n",
       "           u'votes.useful',  u'review_len_wrds',  u'review_len_sent',\n",
       "       u'avg_wrds_in_sent',         u'num_para',   u'mentions_price',\n",
       "            u'num_allcaps', u'num_exclamations',           u'tokens'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('pickled/users_elite.pkl', 'r') as picklefile:\n",
    "    userids = pickle.load(picklefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "userids.set_index('user_id', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t = reviews.loc[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reviews['is_elite'] = reviews.user_id.apply(lambda x: userids.loc[x, 'is_elite'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "elite_reviews = reviews[reviews.is_elite == 1]\n",
    "nonelite_reviews = reviews[reviews.is_elite == 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get most popular tokens for elite users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'place', 422491),\n",
       " (u'good', 414171),\n",
       " (u'like', 373306),\n",
       " (u'food', 337150),\n",
       " (u'time', 295422),\n",
       " (u'come', 277728),\n",
       " (u'great', 265779),\n",
       " (u'order', 255788),\n",
       " (u'try', 199987),\n",
       " (u'service', 191908),\n",
       " (u'love', 165209),\n",
       " (u'nice', 163142),\n",
       " (u've', 162112),\n",
       " (u'think', 156943),\n",
       " (u'look', 152108),\n",
       " (u'want', 148604),\n",
       " (u'little', 146494),\n",
       " (u'eat', 143299),\n",
       " (u'restaurant', 141329),\n",
       " (u'pretty', 140637),\n",
       " (u'know', 137719),\n",
       " (u'drink', 134979),\n",
       " (u'price', 128315),\n",
       " (u'thing', 125599),\n",
       " (u'bar', 120683),\n",
       " (u'menu', 119607),\n",
       " (u'people', 115308),\n",
       " (u'wait', 114556),\n",
       " (u'night', 112406),\n",
       " (u'best', 111804),\n",
       " (u'table', 110382),\n",
       " (u'day', 109613),\n",
       " (u'room', 109387),\n",
       " (u'chicken', 108951),\n",
       " (u'lot', 104989),\n",
       " (u'way', 101484),\n",
       " (u'friend', 99267),\n",
       " (u'definitely', 97970),\n",
       " (u'feel', 97363),\n",
       " (u'vega', 96392),\n",
       " (u'cheese', 96357),\n",
       " (u'sauce', 95872),\n",
       " (u'taste', 95082),\n",
       " (u'right', 93498),\n",
       " (u'need', 93335),\n",
       " (u'better', 92773),\n",
       " (u'star', 92115),\n",
       " (u'delicious', 90004),\n",
       " (u'bit', 89866),\n",
       " (u'friendly', 88523),\n",
       " (u'salad', 85033),\n",
       " (u'experience', 84974),\n",
       " (u'small', 84621),\n",
       " (u'ask', 83991),\n",
       " (u'area', 83797),\n",
       " (u'dish', 83203),\n",
       " (u'enjoy', 82686),\n",
       " (u'burger', 82026),\n",
       " (u'sure', 81446),\n",
       " (u'meal', 81284),\n",
       " (u'flavor', 81002),\n",
       " (u'big', 80961),\n",
       " (u'walk', 80426),\n",
       " (u'work', 80367),\n",
       " (u'll', 79885),\n",
       " (u'hour', 77734),\n",
       " (u'pizza', 77446),\n",
       " (u'check', 77113),\n",
       " (u'staff', 77098),\n",
       " (u'bad', 76747),\n",
       " (u'fresh', 76714),\n",
       " (u'lunch', 76628),\n",
       " (u'new', 76272),\n",
       " (u'location', 75728),\n",
       " (u'wasn', 75512),\n",
       " (u'visit', 74425),\n",
       " (u'use', 73991),\n",
       " (u'sandwich', 72694),\n",
       " (u'serve', 72192),\n",
       " (u'review', 70234),\n",
       " (u'beer', 70072),\n",
       " (u'tell', 69795),\n",
       " (u'minute', 69252),\n",
       " (u'sit', 68311),\n",
       " (u'dinner', 66981),\n",
       " (u'hot', 66715),\n",
       " (u'long', 66198),\n",
       " (u'store', 65083),\n",
       " (u'end', 64738),\n",
       " (u'sweet', 63557),\n",
       " (u'favorite', 62852),\n",
       " (u'amazing', 62453),\n",
       " (u'hotel', 61848),\n",
       " (u'meat', 61226),\n",
       " (u'leave', 60670),\n",
       " (u'year', 60117),\n",
       " (u'special', 59977),\n",
       " (u'happy', 59965),\n",
       " (u'stay', 59679),\n",
       " (u'open', 58600)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elite_features = vectorizer.fit_transform(elite_reviews.tokens)\n",
    "words = vectorizer.get_feature_names()\n",
    "elite_features = elite_features.toarray()\n",
    "dist = np.sum(elite_features, axis = 0)\n",
    "sorted(zip(words, dist), key = lambda x: x[1], reverse = True)[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test model?\n",
    "vectorizer = CountVectorizer(analyzer = \"word\",   \\\n",
    "                             tokenizer = None,    \\\n",
    "                             preprocessor = None, \\\n",
    "                             stop_words = None, \\\n",
    "                             max_features = 500) \n",
    "features = vectorizer.fit_transform(reviews.tokens)\n",
    "words = vectorizer.get_feature_names()\n",
    "features = features.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'place', 1347563),\n",
       " (u'good', 1237040),\n",
       " (u'food', 1206517),\n",
       " (u'great', 1039474),\n",
       " (u'time', 987742),\n",
       " (u'like', 977408),\n",
       " (u'come', 834873),\n",
       " (u'service', 815935),\n",
       " (u'order', 767823),\n",
       " (u'try', 597247),\n",
       " (u'love', 531152),\n",
       " (u've', 472226),\n",
       " (u'nice', 469437),\n",
       " (u'look', 456345),\n",
       " (u'want', 445065),\n",
       " (u'restaurant', 430650),\n",
       " (u'price', 426258),\n",
       " (u'eat', 421034),\n",
       " (u'best', 420215),\n",
       " (u'know', 397865),\n",
       " (u'think', 397360),\n",
       " (u'wait', 392371),\n",
       " (u'little', 368174),\n",
       " (u'drink', 354747),\n",
       " (u'staff', 342886),\n",
       " (u'people', 341297),\n",
       " (u'day', 340781),\n",
       " (u'ask', 331337),\n",
       " (u'thing', 330179),\n",
       " (u'friendly', 329725),\n",
       " (u'pretty', 315407),\n",
       " (u'room', 313836),\n",
       " (u'menu', 311748),\n",
       " (u'experience', 311092),\n",
       " (u'need', 308685),\n",
       " (u'tell', 308509),\n",
       " (u'chicken', 308354),\n",
       " (u'work', 308325),\n",
       " (u'night', 298637),\n",
       " (u'bar', 297164),\n",
       " (u'table', 296750),\n",
       " (u'definitely', 296024),\n",
       " (u'way', 289305),\n",
       " (u'better', 285811),\n",
       " (u'feel', 285268),\n",
       " (u'bad', 284377),\n",
       " (u'delicious', 273730),\n",
       " (u'star', 269172),\n",
       " (u'taste', 266005),\n",
       " (u'friend', 263862),\n",
       " (u'right', 262630),\n",
       " (u'lot', 262318),\n",
       " (u'vega', 261591),\n",
       " (u'amazing', 258373),\n",
       " (u'new', 257560),\n",
       " (u'recommend', 255679),\n",
       " (u'hour', 247641),\n",
       " (u'use', 247512),\n",
       " (u'minute', 246556),\n",
       " (u'pizza', 245235),\n",
       " (u'sauce', 234239),\n",
       " (u'sure', 232820),\n",
       " (u'check', 228986),\n",
       " (u'cheese', 227437),\n",
       " (u'year', 225926),\n",
       " (u'walk', 223581),\n",
       " (u'salad', 223537),\n",
       " (u'meal', 222750),\n",
       " (u'fresh', 220706),\n",
       " (u'review', 220601),\n",
       " (u'leave', 219726),\n",
       " (u'burger', 219547),\n",
       " (u'small', 217001),\n",
       " (u'visit', 216077),\n",
       " (u'location', 213373),\n",
       " (u'area', 212612),\n",
       " (u'customer', 211085),\n",
       " (u'enjoy', 210243),\n",
       " (u'bit', 206874),\n",
       " (u'big', 206131),\n",
       " (u'dish', 205793),\n",
       " (u'll', 204150),\n",
       " (u'lunch', 202936),\n",
       " (u'flavor', 196651),\n",
       " (u'pay', 196317),\n",
       " (u'sit', 195513),\n",
       " (u'wasn', 195005),\n",
       " (u'awesome', 193017),\n",
       " (u'long', 191897),\n",
       " (u'clean', 191207),\n",
       " (u'dinner', 188752),\n",
       " (u'stay', 185797),\n",
       " (u'happy', 185574),\n",
       " (u'serve', 183981),\n",
       " (u'sandwich', 181423),\n",
       " (u'server', 180294),\n",
       " (u'favorite', 178743),\n",
       " (u'bring', 178378),\n",
       " (u'beer', 176966),\n",
       " (u'store', 172781)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get counts for each word in corpus \n",
    "dist = np.sum(features, axis = 0)\n",
    "sorted(zip(words, dist), key = lambda x: x[1], reverse = True)[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_estimators = 50).fit(features, test.is_elite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 1.0\n",
      "acc: [ 1.  1.]\n",
      "acc: [ 1.  1.]\n",
      "acc: [ 1.  1.]\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(features)\n",
    "print 'acc:', accuracy_score(test.is_elite, pred)\n",
    "print 'acc:', precision_score(test.is_elite, pred, average = None)\n",
    "print 'acc:', recall_score(test.is_elite, pred, average = None)\n",
    "print 'acc:', f1_score(test.is_elite, pred, average = None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
