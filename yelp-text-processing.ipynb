{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"features: \n",
    "- average sentence length (in words)\n",
    "- average review length (in words)\n",
    "- average review length (in sentences)\n",
    "- paragraph rate\n",
    "- bulleted or numbered list rate\n",
    "- all caps, bad punctuation, run on sentences?\n",
    "- bag of words: common words in elite vs. not elite; fp, fn, etc. \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import string, re\n",
    "import math\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from spacy.en import English, STOPWORDS\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from tqdm import tqdm, tqdm_pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nlp = English()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 767,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d = nltk.Text(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reviews = pd.read_csv('data/yelp_academic_dataset_review.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stop = STOPWORDS\n",
    "punct = {p for p in string.punctuation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get descriptive features of review text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_num_words(text):\n",
    "    \"\"\"Get number of words per review.\"\"\"\n",
    "    return float(len(text.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# no spacy\n",
    "def get_num_sents(text):\n",
    "    \"\"\"Get number of sentences per review.\"\"\"\n",
    "    # add 1 at the end for last punctuation \n",
    "    return text.count('. ') + text.count('! ') + text.count('? ') + text.count(') ') + \\\n",
    "            text.count('.\\n') + text.count('!\\n') + text.count('?\\n') + text.count(')\\n') + 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_num_para(text):\n",
    "    \"\"\"Get number of paragraphs per review.\"\"\"\n",
    "    return text.count('\\n\\n') + 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 929,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mentions_price(text):\n",
    "    \"\"\"Check if review mentions price ($). Return 1 if yes, 0 if no.\"\"\"\n",
    "    return 1 if '$' in text else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 977,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_allcaps(text):\n",
    "    \"\"\"Get number of all uppercase words in review.\"\"\"\n",
    "    text = re.sub(\"[^a-zA-Z]\", \" \", text)\n",
    "    return len([word for word in text.split() if word.isupper() and len(word) > 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 941,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_exclamations(text):\n",
    "    \"\"\"Get number of exclamation marks in review.\"\"\"\n",
    "    return text.count('!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_num_chars(text):\n",
    "    return float(len([char for char in text if char != ' ' and char not in punct]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([         u'user_id',        u'review_id',             u'text',\n",
       "             u'votes.cool',      u'business_id',      u'votes.funny',\n",
       "                  u'stars',             u'date',             u'type',\n",
       "           u'votes.useful',  u'review_len_wrds',  u'review_len_sent',\n",
       "       u'avg_wrds_in_sent',         u'num_para',   u'mentions_price',\n",
       "            u'num_allcaps', u'num_exclamations',           u'tokens',\n",
       "               u'is_elite'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t = reviews.loc[0, 'text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'Mr Hoagie is an institution. Walking in, it does seem like a throwback to 30 years ago, old fashioned menu board, booths out of the 70s, and a large selection of food. Their speciality is the Italian Hoagie, and it is voted the best in the area year after year. I usually order the burger, while the patties are obviously cooked from frozen, all of the other ingredients are very fresh. Overall, its a good alternative to Subway, which is down the road.'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# bulleted or numbered list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 742,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def decode(text):\n",
    "    try:\n",
    "        return text.decode('utf8')\n",
    "    except:\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 866,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# with spacy\n",
    "def get_num_sents_spacy(text):\n",
    "    try:\n",
    "        return len([sent for sent in nlp(text).sents])\n",
    "    except:\n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get tokens -- *not currently implemented*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_clean_tokens(text):\n",
    "    #letters_only = re.sub(\"[^a-zA-Z]\", \" \", text) \n",
    "    union = punct.union(stop)\n",
    "    #spacing = {'', ' ', '\\n', '\\n\\n'}\n",
    "    tokens = [token.lemma_ for token in nlp(text.decode('utf8'))]\n",
    "    filtered = [token for token in tokens if token not in union]\n",
    "    while \"\" in filtered:\n",
    "        filtered.remove(\"\")\n",
    "    while \" \" in filtered:\n",
    "        filtered.remove(\" \")\n",
    "    while \"\\n\" in filtered:\n",
    "        filtered.remove(\"\\n\")\n",
    "    while \"\\n\\n\" in filtered:\n",
    "        filtered.remove(\"\\n\\n\")\n",
    "    return ' '.join(filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# version without utf decoding\n",
    "# def get_clean_tokens2(text):  \n",
    "#     letters_only = re.sub(\"[^a-zA-Z]\", \" \", text) \n",
    "#     words = ' '.join(letters_only.lower().split())\n",
    "#     tokens = [token.lemma_ for token in nlp(words)]\n",
    "#     filtered = [t for t in tokens if t not in stop and t != '' and t != ' ' and t != '\\n' and t != '\\n\\n']\n",
    "#     return ' '.join(filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1014,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# uses utf decoding\n",
    "def get_clean_tokens2(text):  \n",
    "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", text) \n",
    "    words = ' '.join(letters_only.lower().split())\n",
    "    tokens = [token.lemma_ for token in nlp(words)]\n",
    "    filtered = [t for t in tokens if t not in stop and t != '' and t != ' ' and t != '\\n' and t != '\\n\\n']\n",
    "    return ' '.join(filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1032,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokenize2(df):\n",
    "    return map(get_clean_tokens2, df.text.values)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1067,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokenize4(df):\n",
    "    tokens = []\n",
    "    for i in tqdm(range(len(df.text.values))):\n",
    "        tokens.append(get_clean_tokens2(df.text.values[i]))\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1071,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "clntkns = tokenize4(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1075,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('pickled/tokens.pkl', 'w') as picklefile:\n",
    "    pickle.dump(clntkns, picklefile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### parse reviews df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### OLD\n",
    "def get_features_old(df):\n",
    "    # get number of words in single review\n",
    "    df.loc[:,'review_len_wrds'] = df.loc[:,'text'].apply(lambda x: len(cleantext(x)))\n",
    "    \n",
    "    # get number of sentences in single review\n",
    "    df.loc[:,'review_len_sent'] = df.loc[:,'text'].apply(\n",
    "        lambda x: len([sent for sent in nlp(x.decode('utf8')).sents])) # better way?\n",
    "    \n",
    "    # get average number of words per sentence \n",
    "    df.loc[:,'avg_wrds_in_sent'] = df.loc[:,'review_len_wrds'] / df.loc[:,'review_len_sent']\n",
    "    \n",
    "    # get cleaned tokens for bag of words\n",
    "    df.loc[:,'clean_tkns'] = df.loc[:, 'text'].apply(lambda x: get_clean_tokens(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 969,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_features(df):\n",
    "#     decode\n",
    "    df.loc[:, 'text'] = df.loc[:, 'text'].apply(decode)\n",
    "\n",
    "    # get number of words in single review\n",
    "    df.loc[:,'review_len_wrds'] = df.loc[:,'text'].apply(get_num_words)\n",
    "\n",
    "    #get number of sentences in single review\n",
    "    df.loc[:,'review_len_sent'] = df.loc[:,'text'].apply(get_num_sents)\n",
    "\n",
    "    # get average number of words per sentence \n",
    "    df.loc[:,'avg_wrds_in_sent'] = df.loc[:,'review_len_wrds'] / df.loc[:,'review_len_sent']\n",
    "    \n",
    "    # get number of paragraphs\n",
    "    df.loc[:, 'num_para'] = df.loc[:, 'text'].apply(get_num_para)\n",
    "    \n",
    "    # check if price is mentioned\n",
    "    df.loc[:, 'mentions_price'] = df.loc[:, 'text'].apply(mentions_price)\n",
    "    \n",
    "    # get number of all caps words\n",
    "    df.loc[:, 'num_allcaps'] = df.loc[:, 'text'].apply(get_allcaps)\n",
    "    \n",
    "    # get number of exclamation marks\n",
    "    df.loc[:, 'num_exclamations'] = df.loc[:, 'text'].apply(get_exclamations)\n",
    "\n",
    "#     get cleaned tokens for bag of words\n",
    "#     %time df.loc[:,'clean_tkns'] = df.loc[:, 'text'].apply(lambda x: get_clean_tokens2(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nARI (automatic readability index) score:\\nwhere characters is the number of letters and numbers, words is the number of spaces, \\nand sentences is the number of sentences. \\n'"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# additional stuff - add to previous cell when cleaning\n",
    "def get_more_features(df):\n",
    "    df.loc[:,'num_chars'] = df.loc[:,'text'].apply(get_num_chars)\n",
    "    df.loc[:,'ari_score'] = df.apply(\n",
    "        lambda row: 4.71 * (row.num_chars/float(row.review_len_wrds)) \\\n",
    "        + 0.5 * (row.review_len_wrds/float(row.review_len_sent)) - 21.43, \n",
    "        axis = 1)\n",
    "    \n",
    "\"\"\"\n",
    "ARI (automatic readability index) score:\n",
    "where characters is the number of letters and numbers, words is the number of spaces, \n",
    "and sentences is the number of sentences. \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([         u'user_id',        u'review_id',             u'text',\n",
       "             u'votes.cool',      u'business_id',      u'votes.funny',\n",
       "                  u'stars',             u'date',             u'type',\n",
       "           u'votes.useful',  u'review_len_wrds',  u'review_len_sent',\n",
       "       u'avg_wrds_in_sent',         u'num_para',   u'mentions_price',\n",
       "            u'num_allcaps', u'num_exclamations',           u'tokens',\n",
       "               u'is_elite',        u'num_chars',        u'ari_score'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_chars_per_word(df):\n",
    "    df['avg_chars_per_word'] = df.loc[:,'num_chars'] / df.loc[:,'review_len_wrds']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "get_chars_per_word(reviews)\n",
    "get_features(reviews)\n",
    "get_more_features(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "byuser = reviews.groupby('user_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "user_ari = byuser.mean().loc[:,'ari_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "user_wrd_length = byuser.mean().loc[:,'avg_chars_per_word']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1003,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "user_avgs = byuser.mean().loc[:, 'review_len_wrds':]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1009,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# pickle user avgs data\n",
    "with open('pickled/user_avgs.pkl', 'w') as picklefile:\n",
    "    pickle.dump(user_avgs, picklefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pickle user avg ari data\n",
    "with open('pickled/user_ari.pkl', 'w') as picklefile:\n",
    "    pickle.dump(user_ari, picklefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pickle user avg word length data\n",
    "with open('pickled/user_wrdlength.pkl', 'w') as picklefile:\n",
    "    pickle.dump(user_wrd_length, picklefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1077,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reviews['tokens'] = clntkns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('pickled/reviewsdf2.pkl', 'w') as picklefile:\n",
    "    pickle.dump(reviews, picklefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('pickled/reviewsdf2.pkl', 'r') as picklefile:\n",
    "    reviews = pickle.load(picklefile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bag of words, etc. workspace "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('pickled/users_elite.pkl', 'r') as picklefile:\n",
    "    userids = pickle.load(picklefile)\n",
    "    \n",
    "userids.set_index('user_id', inplace = True)\n",
    "reviews['is_elite'] = reviews.user_id.apply(lambda x: userids.loc[x, 'is_elite'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "split into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train, test = train_test_split(reviews, test_size = .25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "elite_reviews = train[train.is_elite == 1]\n",
    "nonelite_reviews = train[train.is_elite == 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "define word vector parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(analyzer = \"word\",   \\\n",
    "                             tokenizer = None,    \\\n",
    "                             preprocessor = None, \\\n",
    "                             stop_words = None, \\\n",
    "                             max_features = 500) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get most popular tokens for elite users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "elite_features = vectorizer.fit_transform(elite_reviews.tokens)\n",
    "elite_words = vectorizer.get_feature_names()\n",
    "elite_features = elite_features.toarray()\n",
    "elite_dist = np.sum(elite_features, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "elite_sorted = sorted(zip(elite_words, elite_dist), key = lambda x: x[1], reverse = True)\n",
    "elite_wrds_dict = dict(elite_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "onlyelite_words = {\n",
    "    word : elite_wrds_dict[word] \n",
    "    for word in elite_wrds_dict \n",
    "    if word not in nonelite_wrds_dict}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'locate', 19308),\n",
       " (u'space', 18632),\n",
       " (u'crispy', 16606),\n",
       " (u'butter', 15524),\n",
       " (u'le', 15204),\n",
       " (u'pepper', 14970),\n",
       " (u'grab', 14605),\n",
       " (u'dance', 14596),\n",
       " (u'mushroom', 14517),\n",
       " (u'brunch', 14501),\n",
       " (u'sound', 14203),\n",
       " (u'tender', 13972),\n",
       " (u'standard', 13696),\n",
       " (u'toast', 13672),\n",
       " (u'mall', 13671),\n",
       " (u'note', 13661),\n",
       " (u'soft', 13526),\n",
       " (u'dip', 13510),\n",
       " (u'black', 13384),\n",
       " (u'center', 13354),\n",
       " (u'et', 13208),\n",
       " (u'event', 13173),\n",
       " (u'ton', 13114),\n",
       " (u'salmon', 12883),\n",
       " (u'seafood', 12819),\n",
       " (u'cute', 12809),\n",
       " (u'cafe', 12762),\n",
       " (u'interesting', 12732),\n",
       " (u'flavorful', 12620),\n",
       " (u'section', 12471),\n",
       " (u'sausage', 12351),\n",
       " (u'fruit', 12172),\n",
       " (u'spice', 12105),\n",
       " (u'idea', 12065),\n",
       " (u'corn', 11999),\n",
       " (u'sort', 11893),\n",
       " (u'hang', 11877),\n",
       " (u'wrap', 11833),\n",
       " (u'pour', 11769),\n",
       " (u'rock', 11742),\n",
       " (u'mac', 11733),\n",
       " (u'middle', 11701),\n",
       " (u'station', 11647),\n",
       " (u'unique', 11622),\n",
       " (u'compare', 11583),\n",
       " (u'crust', 11514),\n",
       " (u'joint', 11456),\n",
       " (u'sample', 11443),\n",
       " (u'ticket', 11428),\n",
       " (u'pie', 11318)]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# top 20 words used by elites but not non-elites\n",
    "sorted(onlyelite_words.items(), key = lambda x: x[1], reverse = True)[:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get popular tokens for non-elite users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nonelite_features = vectorizer.fit_transform(nonelite_reviews.tokens)\n",
    "nonelite_words = vectorizer.get_feature_names()\n",
    "nonelite_features = nonelite_features.toarray()\n",
    "nonelite_dist = np.sum(nonelite_features, axis = 0)\n",
    "nonelite_sorted = sorted(zip(nonelite_words, nonelite_dist), key = lambda x: x[1], reverse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nonelite_wrds_dict = dict(nonelite_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "onlynonelite_words = {\n",
    "    word : nonelite_wrds_dict[word] \n",
    "    for word in nonelite_wrds_dict \n",
    "    if word not in elite_wrds_dict}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'manager', 66142),\n",
       " (u'hair', 48765),\n",
       " (u'phone', 42729),\n",
       " (u'company', 41832),\n",
       " (u'receive', 39751),\n",
       " (u'nail', 39224),\n",
       " (u'thank', 39026),\n",
       " (u'rude', 36485),\n",
       " (u'fix', 36223),\n",
       " (u'professional', 35974),\n",
       " (u'horrible', 33552),\n",
       " (u'appointment', 32534),\n",
       " (u'office', 31827),\n",
       " (u'dr', 31712),\n",
       " (u'min', 31441),\n",
       " (u'speak', 30116),\n",
       " (u'explain', 29773),\n",
       " (u'thanks', 29761),\n",
       " (u'twice', 28396),\n",
       " (u'terrible', 28270),\n",
       " (u'send', 27595),\n",
       " (u'question', 27520),\n",
       " (u'understand', 27486),\n",
       " (u'purchase', 27432),\n",
       " (u'salon', 26985),\n",
       " (u'disappointed', 26105),\n",
       " (u'completely', 26035),\n",
       " (u'die', 25317),\n",
       " (u'massage', 25159),\n",
       " (u'provide', 24999),\n",
       " (u'greet', 24300),\n",
       " (u'break', 24279),\n",
       " (u'hope', 24220),\n",
       " (u'save', 23840),\n",
       " (u'complaint', 23475),\n",
       " (u'product', 23364),\n",
       " (u'boyfriend', 23210),\n",
       " (u'desk', 23078),\n",
       " (u'welcome', 22699),\n",
       " (u'deliver', 22603),\n",
       " (u'state', 22580),\n",
       " (u'dollar', 22557),\n",
       " (u'woman', 22533),\n",
       " (u'answer', 22099),\n",
       " (u'guest', 22045),\n",
       " (u'poor', 21945),\n",
       " (u'number', 21740),\n",
       " (u'daughter', 21615),\n",
       " (u'request', 21537),\n",
       " (u'authentic', 21384)]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# top 20 words used by elites but not non-elites\n",
    "sorted(onlynonelite_words.items(), key = lambda x: x[1], reverse = True)[:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### some other stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test model?\n",
    "features = vectorizer.fit_transform(train.tokens)\n",
    "words = vectorizer.get_feature_names()\n",
    "features = features.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'place', 1347563),\n",
       " (u'good', 1237040),\n",
       " (u'food', 1206517),\n",
       " (u'great', 1039474),\n",
       " (u'time', 987742),\n",
       " (u'like', 977408),\n",
       " (u'come', 834873),\n",
       " (u'service', 815935),\n",
       " (u'order', 767823),\n",
       " (u'try', 597247),\n",
       " (u'love', 531152),\n",
       " (u've', 472226),\n",
       " (u'nice', 469437),\n",
       " (u'look', 456345),\n",
       " (u'want', 445065),\n",
       " (u'restaurant', 430650),\n",
       " (u'price', 426258),\n",
       " (u'eat', 421034),\n",
       " (u'best', 420215),\n",
       " (u'know', 397865),\n",
       " (u'think', 397360),\n",
       " (u'wait', 392371),\n",
       " (u'little', 368174),\n",
       " (u'drink', 354747),\n",
       " (u'staff', 342886),\n",
       " (u'people', 341297),\n",
       " (u'day', 340781),\n",
       " (u'ask', 331337),\n",
       " (u'thing', 330179),\n",
       " (u'friendly', 329725),\n",
       " (u'pretty', 315407),\n",
       " (u'room', 313836),\n",
       " (u'menu', 311748),\n",
       " (u'experience', 311092),\n",
       " (u'need', 308685),\n",
       " (u'tell', 308509),\n",
       " (u'chicken', 308354),\n",
       " (u'work', 308325),\n",
       " (u'night', 298637),\n",
       " (u'bar', 297164),\n",
       " (u'table', 296750),\n",
       " (u'definitely', 296024),\n",
       " (u'way', 289305),\n",
       " (u'better', 285811),\n",
       " (u'feel', 285268),\n",
       " (u'bad', 284377),\n",
       " (u'delicious', 273730),\n",
       " (u'star', 269172),\n",
       " (u'taste', 266005),\n",
       " (u'friend', 263862),\n",
       " (u'right', 262630),\n",
       " (u'lot', 262318),\n",
       " (u'vega', 261591),\n",
       " (u'amazing', 258373),\n",
       " (u'new', 257560),\n",
       " (u'recommend', 255679),\n",
       " (u'hour', 247641),\n",
       " (u'use', 247512),\n",
       " (u'minute', 246556),\n",
       " (u'pizza', 245235),\n",
       " (u'sauce', 234239),\n",
       " (u'sure', 232820),\n",
       " (u'check', 228986),\n",
       " (u'cheese', 227437),\n",
       " (u'year', 225926),\n",
       " (u'walk', 223581),\n",
       " (u'salad', 223537),\n",
       " (u'meal', 222750),\n",
       " (u'fresh', 220706),\n",
       " (u'review', 220601),\n",
       " (u'leave', 219726),\n",
       " (u'burger', 219547),\n",
       " (u'small', 217001),\n",
       " (u'visit', 216077),\n",
       " (u'location', 213373),\n",
       " (u'area', 212612),\n",
       " (u'customer', 211085),\n",
       " (u'enjoy', 210243),\n",
       " (u'bit', 206874),\n",
       " (u'big', 206131),\n",
       " (u'dish', 205793),\n",
       " (u'll', 204150),\n",
       " (u'lunch', 202936),\n",
       " (u'flavor', 196651),\n",
       " (u'pay', 196317),\n",
       " (u'sit', 195513),\n",
       " (u'wasn', 195005),\n",
       " (u'awesome', 193017),\n",
       " (u'long', 191897),\n",
       " (u'clean', 191207),\n",
       " (u'dinner', 188752),\n",
       " (u'stay', 185797),\n",
       " (u'happy', 185574),\n",
       " (u'serve', 183981),\n",
       " (u'sandwich', 181423),\n",
       " (u'server', 180294),\n",
       " (u'favorite', 178743),\n",
       " (u'bring', 178378),\n",
       " (u'beer', 176966),\n",
       " (u'store', 172781)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get counts for each word in corpus \n",
    "dist = np.sum(features, axis = 0)\n",
    "sorted(zip(words, dist), key = lambda x: x[1], reverse = True)[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = GaussianNB().fit(features, train.is_elite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1683421    use noble cleaner rental clean carpet home ext...\n",
       "110536     phoenix night business recently hilton mesa gr...\n",
       "1020063    people ask like wendy burger mcdonalds instead...\n",
       "930773     service happy hour bar area service actual res...\n",
       "1201759    fresh produce rarely fresh bough box triple wa...\n",
       "1365051    authentic chai edinburgh little place gorgeous...\n",
       "2071758    impressed selection ve stay store hour flavor ...\n",
       "2095507    look high quality abd healthy food protein sou...\n",
       "692971     come branch longer veggie burger people u thei...\n",
       "1865827    suppose sexy cirque du soleil bare boob buff d...\n",
       "2169360    absolutely delicious food quick friendly servi...\n",
       "1468432    try place fish disappoint people hostess stand...\n",
       "644146     twice sunday brunch wedding anniversary time e...\n",
       "909549     start pride merlot best merlot drink progress ...\n",
       "460045     attorney isn t cheap definitely best result mo...\n",
       "658829     picture coca cola polar bear receive coupon fr...\n",
       "1235821    yesterday time bump star italian beef time pro...\n",
       "1937180    want american cheeseburger play simple pro gam...\n",
       "139885     read andrea r review village realize switch lo...\n",
       "791235     pet store friend pick dog pretty sadden saw wa...\n",
       "822423     cool hotel come anniversary little ago lot bet...\n",
       "119039     best japanese din year husband consistent exce...\n",
       "581494     matts big breakfast great frequently yes small...\n",
       "576703     weakness good steak tend enjoy steakhouse prim...\n",
       "831476     favorite spot m oakland school work m pescatar...\n",
       "641531     brother marry sep look small wedding manage fi...\n",
       "307172     read review wonder place usually restaurant fo...\n",
       "11690      place best pizza ve keste paulie g nyc wood gr...\n",
       "649860            dig place element require proper seduction\n",
       "2213046    sit white comfy sofa aware service talk differ...\n",
       "                                 ...                        \n",
       "16986      contrary popular belief blumenthal perform art...\n",
       "2029201    best ayce sushi ve place nice worker nice dish...\n",
       "1211628    appointment shampoo blow dry tell cost tell ne...\n",
       "788165     quick return time wart remove freeze decide t ...\n",
       "997865     delicious sandwich smoked meat incredible smok...\n",
       "794077     dinner month joe miami dinner joe vega week ag...\n",
       "649035     love place great mexican food love staff atten...\n",
       "1557643    randomly come spoonz cafe wander downtown phoe...\n",
       "795871               great tapas decent mildly aloof service\n",
       "239001     best restaurant experience pittsburgh extremel...\n",
       "1033262    kid fly airline bus rude consistently rude fli...\n",
       "281198     hertz gold member year love perk customer serv...\n",
       "944996     husband improtu dinner date cork friday watch ...\n",
       "1306767    simple nail tire tell patch need new tire husb...\n",
       "2087943    awesome delicious food friendly staff nice atm...\n",
       "593981     ve savour memory recent meal quick weekend get...\n",
       "1028027    cozy place authentic greek menu helpful staff try\n",
       "1108421    mgm poker room stage deli s sandwich like pean...\n",
       "2005438    t avoid christmas market behemoth centre edinb...\n",
       "859605     sit bar friday night friend appetizer drink u ...\n",
       "2059011    friendly service good food layout table chair ...\n",
       "569728     prime rib check snow crab leg check countless ...\n",
       "1822543    great time staff great work hard sure experien...\n",
       "723354     complaint moment cable internet phone complain...\n",
       "437953     work angie s aesthetic brief time wow place sp...\n",
       "1575400    come family try new scottsdale u visit town di...\n",
       "1455471    breakfast ok burger lunch delicious enjoy wait...\n",
       "979494     wife th birthday perfect food service wine sel...\n",
       "265720     date visit future wiffy step prior madison hal...\n",
       "182862     wonderful fleet aircraft experience pilot righ...\n",
       "Name: tokens, dtype: object"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.float64' object has no attribute 'lower'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-301-0ff37e7df340>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/sklearn/feature_extraction/text.pyc\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m    815\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    816\u001b[0m         vocabulary, X = self._count_vocab(raw_documents,\n\u001b[0;32m--> 817\u001b[0;31m                                           self.fixed_vocabulary_)\n\u001b[0m\u001b[1;32m    818\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    819\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/sklearn/feature_extraction/text.pyc\u001b[0m in \u001b[0;36m_count_vocab\u001b[0;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[1;32m    750\u001b[0m         \u001b[0mindptr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    751\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mraw_documents\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 752\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0;32min\u001b[0m \u001b[0manalyze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    753\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    754\u001b[0m                     \u001b[0mj_indices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocabulary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/sklearn/feature_extraction/text.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(doc)\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m             return lambda doc: self._word_ngrams(\n\u001b[0;32m--> 238\u001b[0;31m                 tokenize(preprocess(self.decode(doc))), stop_words)\n\u001b[0m\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/sklearn/feature_extraction/text.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlowercase\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstrip_accents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mstrip_accents\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.float64' object has no attribute 'lower'"
     ]
    }
   ],
   "source": [
    "test_features = vectorizer.fit_transform(test.tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_features = test_features.toarray()\n",
    "test_pred = model.predict(test_features)\n",
    "print accuracy_score(train.is_elite, pred)\n",
    "print precision_score(train.is_elite, pred)\n",
    "print recall_score(train.is_elite, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = model.predict(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.727847081121\n",
      "0.448259404194\n",
      "0.485176924527\n"
     ]
    }
   ],
   "source": [
    "print accuracy_score(train.is_elite, pred)\n",
    "print precision_score(train.is_elite, pred)\n",
    "print recall_score(train.is_elite, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 1.0\n",
      "acc: [ 1.  1.]\n",
      "acc: [ 1.  1.]\n",
      "acc: [ 1.  1.]\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(features)\n",
    "print 'acc:', accuracy_score(test.is_elite, pred)\n",
    "print 'acc:', precision_score(test.is_elite, pred, average = None)\n",
    "print 'acc:', recall_score(test.is_elite, pred, average = None)\n",
    "print 'acc:', f1_score(test.is_elite, pred, average = None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
